{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OMe_gfW5lVs"
      },
      "source": [
        "# Modelo simple\n",
        "\n",
        "En este notebook van a encontrar un modelo de ML simple para clasificar especies de iris.\n",
        "\n",
        "Lo utilizaremos para aprender a pasar de jupyter notebooks (.ipynb) a archivos .py\n",
        "\n",
        "Durante el proceso utilizaremos git para controlar versiones.\n",
        "\n",
        "Los datos pueden encontrarlos en: https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Jmz72p4l8pMc"
      },
      "source": [
        "Con el siguiente comando podemos descargar el dataset:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lrQSMCdd-G9X",
        "outputId": "6f8f8408-1684-4511-fd65-e7e3c2f2b8ae"
      },
      "outputs": [],
      "source": [
        "#!curl -o \"iris.csv\" \"https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2aLazYMB_CEi"
      },
      "source": [
        "EJERCICIO: Correr el comando en una terminal (local)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mix9n3CrOGhC"
      },
      "source": [
        "Ahora, leemos el dataset con pandas y entrenamos un modelo de clasificación (muy simple, sin nada de pre procesamiento)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A7UJZlZs8zG-"
      },
      "outputs": [],
      "source": [
        "import pandas as pd"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UuGWzp8ZOMSA"
      },
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"C:/Users/Hugo/Curso DS/datasets/iris.csv\")\n",
        "#df = pd.read_csv(\"https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "TdaCJBr3OQAZ",
        "outputId": "bf1fac9c-cb42-49ea-b1d4-02c8a7cb6fc9"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_BvBQ8WfOyl9"
      },
      "source": [
        "Separamos en X e y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X6EgM_MyORQO"
      },
      "outputs": [],
      "source": [
        "X = df.drop(\"variety\", axis=1).values.copy()\n",
        "y = df.variety.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1tnC0HbpOz84"
      },
      "source": [
        "Instanciamos el modelo"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Raq2vYeXOX2m"
      },
      "outputs": [],
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "clf = RandomForestClassifier(max_depth=2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "alQhLQnrO3A9"
      },
      "source": [
        "Lo entrenamos"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d61_mvXEO4VO",
        "outputId": "6bd514b0-9e8e-44f3-f527-6d9fa51feaeb"
      },
      "outputs": [],
      "source": [
        "clf.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pd8KsR6mOlyJ",
        "outputId": "47eee1c6-844b-4c7d-c679-184065f4b500"
      },
      "outputs": [],
      "source": [
        "clf.score(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S1OZ7wfOO5ZQ"
      },
      "source": [
        "Y para predecir:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z1jfy0SvO69R",
        "outputId": "fb9f4e7f-8843-4aec-b142-1c335f2f4f2b"
      },
      "outputs": [],
      "source": [
        "clf.predict([[0.5, 0.5, 0.5, 0.5]])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Y-gQCBbxPK0D"
      },
      "source": [
        "Ahora la idea es llevar esto a un script de python. Primero que nada, vamos a crear un repositorio vacío en github. Luego:\n",
        "\n",
        "1. Crear nuevo proyecto de python (pycharm, visual studio code o algún IDE)\n",
        "2. Crear el primer commit del proyecto y pushearlo\n",
        "3. Correr el script main.py:\n",
        "\n",
        "```\n",
        "# This is a sample Python script.\n",
        "\n",
        "def print_hi(name):\n",
        "    # Use a breakpoint in the code line below to debug your script.\n",
        "    print(f'Hi, {name}')  # Press Ctrl+F8 to toggle the breakpoint.\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    print_hi('PyCharm')\n",
        "\n",
        "```\n",
        "\n",
        "4. Probar pdb (debugger) en la función print_hi(name)\n",
        "\n",
        "5. Crear una nueva rama (puede llamarse por ejemplo \"iris_model\" y moverse a la misma.\n",
        "\n",
        "6. Crear el archivo requirements.txt:\n",
        "\n",
        "\n",
        "\n",
        "```\n",
        "requests\n",
        "pandas\n",
        "sklearn\n",
        "```\n",
        "\n",
        "7. Instalar las dependencias: pip install -r requirements.txt\n",
        "\n",
        "8. Crear los directorios \"ml\" y \"data\" en el proyecto. Dentro de \"ml\" crear los archivos:\n",
        "- \\_\\_init__.py\n",
        "- model.py\n",
        "\n",
        "Dentro de \"data\" crear los archivos:\n",
        "- get_data.py\n",
        "- \\_\\_init__.py\n",
        "\n",
        "9. Crear el archivo .gitignore para ignorar lo que termine en .csv\n",
        "\n",
        "10. Hacer un commit y push con estos archivos vacios\n",
        "\n",
        "11. En el script get_data.py: \n",
        "\n",
        "```\n",
        "import requests\n",
        "\n",
        "\n",
        "url = 'https://gist.githubusercontent.com/netj/8836201/raw/6f9306ad21398ea43cba4f7d537619d0e07d5ae3/iris.csv'\n",
        "r = requests.get(url)\n",
        "\n",
        "open('./data/iris.csv', 'wb').write(r.content)\n",
        "```\n",
        "\n",
        "Esto nos debería descargar el archivo csv. Este archivo no se debe subir al repositorio (no es una buena práctica), por esto lo ponemos en el .gitignore.\n",
        "\n",
        "12. Ahora, en model.py debemos llevar el código de este notebook a un archivo.py:\n",
        "- Leer el dataset\n",
        "- Separar en X e y\n",
        "- Instanciar un modelo random forest\n",
        "- Entrenar el modelo\n",
        "\n",
        "13. Una vez que tenemos el modelo entrenado, podemos persistir el mismo (guardarlo entrenado). Hay distintas formas de hacerlo, una muy común es utilizando pickle. El siguiente artículo puede ser de ayuda:https://machinelearningmastery.com/save-load-machine-learning-models-python-scikit-learn/\n",
        "\n",
        "Guardar el modelo entrenado en el directorio \"ml\".\n",
        "\n",
        "El script de entrenamiento del modelo debería verse algo así:\n",
        "\n",
        "```\n",
        "import pandas as pd\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import os\n",
        "import pickle\n",
        "\n",
        "df = pd.read_csv(f\"{os.getcwd()}/data/iris.csv\")\n",
        "\n",
        "X = df.drop(\"variety\", axis=1).values.copy()\n",
        "y = df.variety.copy()\n",
        "\n",
        "clf = RandomForestClassifier(max_depth=2)\n",
        "\n",
        "clf.fit(X, y)\n",
        "\n",
        "pickle.dump(clf, open(f\"{os.getcwd()}/ml/model.pkl\", 'wb'))\n",
        "```\n",
        "\n",
        "\n",
        "14. Agregar un nuevo archivo en el directorio \"ml\" que se llame \"predict.py\". Este archivo debe tener una función que se llame \"predict(data)\" y reciba \"data\" para generar predicciones. Acá vamos a necesitar usar el modelo previamente entrenado.\n",
        "\n",
        "Además, para practicar, vamos a hacer que el script tome como parámetro un argumento que nos diga donde estan los datos.\n",
        "\n",
        "Podemos pasar el argumento de la siguiente forma:\n",
        "\n",
        "`python ./ml/predict.py /data/iris.csv`\n",
        "\n",
        "\n",
        "El script para generar predicciones, debería ser algo como esto (con varias cosas por mejorar):\n",
        "\n",
        "\n",
        "```\n",
        "import pickle\n",
        "import sys\n",
        "import pandas as pd\n",
        "import os\n",
        "\n",
        "\n",
        "def predict(data):\n",
        "    model = pickle.load(open(f\"{os.getcwd()}/ml/model.pkl\", 'rb'))\n",
        "    preds = model.predict(data)\n",
        "    preds = pd.DataFrame(preds)\n",
        "    preds.to_csv(f\"{os.getcwd()}/data/predictions.csv\")\n",
        "\n",
        "\n",
        "if __name__ == '__main__':\n",
        "    data_dir = sys.argv[1]\n",
        "    data = pd.read_csv(f\"{os.getcwd()}{data_dir}\")\n",
        "    data = data[[\"sepal.length\", \"sepal.width\",  \"petal.length\",  \"petal.width\"]].values\n",
        "    predict(data)\n",
        "```\n",
        "\n",
        "if __name__ == '__main__':\n",
        "\n",
        "Este bloque de código se va a ejecutar siempre que ejecutemos nuestro script de python directamente desde la terminal. Si llamamos a nuestro script desde otro módulo, no se ejecutará.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "modelo_simple.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "base",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.7"
    },
    "vscode": {
      "interpreter": {
        "hash": "892d461b55a6ce994a56bafd67ae2f3489d9f23234c096cfb51dfe498c166e4b"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
